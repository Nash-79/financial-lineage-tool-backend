# Local development stack - NO CLOUD COSTS
# Uses free, open-source alternatives

services:
  # Qdrant Vector Database (replaces Azure AI Search)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - "6333:6333" # REST API
      - "6334:6334" # gRPC
    volumes:
      - qdrant-data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: [ "CMD", "cat", "/etc/hosts" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '2.0'
    networks:
      - lineage-local

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
    networks:
      - lineage-local

  # Local API (connects to Ollama on host)
  api:
    build:
      context: .
      dockerfile: Dockerfile.local
    container_name: lineage-api
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      # Ollama runs on host machine
      - OLLAMA_HOST=http://host.docker.internal:11434
      - LLM_MODEL=llama3.1:8b
      - EMBEDDING_MODEL=nomic-embed-text
      # Local services
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      # Local storage
      - STORAGE_PATH=/app/data
      # LlamaIndex configuration
      - USE_LLAMAINDEX=true
      # DuckDB mode (embedded for persistence)
      - DUCKDB_MODE=embedded
      - DUCKDB_PATH=/app/data/lineage.duckdb
    volumes:
      - ./src:/app/src:ro
      - ./config:/app/config:ro
      - ./demo_data:/app/demo_data:ro
      - ./data:/app/data:rw
      - ./logs:/app/logs
    depends_on:
      qdrant:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    stop_grace_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
    extra_hosts:
      - "host.docker.internal:host-gateway"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - lineage-local

  # Jupyter for exploration (optional)
  jupyter:
    image: jupyter/scipy-notebook:latest
    container_name: lineage-jupyter
    ports:
      - "8888:8888"
    environment:
      - JUPYTER_ENABLE_LAB=yes
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./src:/home/jovyan/src:ro
    networks:
      - lineage-local

  # Frontend (React + Nginx)
  frontend:
    build:
      context: ../financial-lineage-tool-frontend
      dockerfile: Dockerfile
    container_name: lineage-frontend
    ports:
      - "8080:80"
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - lineage-local

volumes:
  qdrant-data:
  redis-data:


networks:
  lineage-local:
    driver: bridge
