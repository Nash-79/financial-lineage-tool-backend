# Environment Configuration Example
# Copy this file to .env and fill in your actual values
# IMPORTANT: Never commit .env to version control

# ===================================
# ENVIRONMENT
# ===================================
# Options: development, staging, production
# Production mode enforces strict validation of required credentials
ENVIRONMENT=development

# ===================================
# SECURITY (REQUIRED IN PRODUCTION)
# ===================================
# JWT secret key for token signing (min 32 characters in production)
# Generate with: openssl rand -hex 32
JWT_SECRET_KEY=

# JWT token expiration in hours (default: 24)
JWT_EXPIRATION_HOURS=24

# CORS allowed origins (comma-separated, no spaces)
# Example: https://app.example.com,https://admin.example.com
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080

# ===================================
# DATABASE CREDENTIALS
# ===================================
# Neo4j graph database
# REQUIRED IN PRODUCTION - Cloud option: Get a free AuraDB instance from https://neo4j.com/cloud/aura-free/
# Local option: Use docker-compose.neo4j.yml for local Neo4j instance
NEO4J_URI=neo4j+s://your-aura-db-uri.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=
NEO4J_DATABASE=neo4j

# ===================================
# INFERENCE FALLBACK (OPTIONAL - FOR CLOUD PROVIDERS)
# ===================================
# Fallback provider when Ollama is unavailable: openrouter, none
INFERENCE_FALLBACK_PROVIDER=openrouter

# OpenRouter API key (free tier available)
# Get at: https://openrouter.ai/
OPENROUTER_API_KEY=

# Default model for cloud fallback
# NOTE: OpenRouter calls are restricted to free-tier models and will be
# downgraded to google/gemini-2.0-flash-exp:free if a non-free model is requested.
# Free-tier models: google/gemini-2.0-flash-exp:free, mistralai/mistral-7b-instruct:free,
# mistralai/devstral-2512:free, meta-llama/llama-3.1-8b-instruct:free, deepseek/deepseek-r1-0528:free
INFERENCE_DEFAULT_MODEL=google/gemini-2.0-flash-exp:free

# ===================================
# OLLAMA (LOCAL LLM)
# ===================================
# For Docker: use http://host.docker.internal:11434
# For local development: use http://localhost:11434
OLLAMA_HOST=http://localhost:11434
LLM_MODEL=llama3.1:8b
EMBEDDING_MODEL=nomic-embed-text
OLLAMA_CONTEXT_WINDOW=4096
# Use quantized models for 50% memory reduction (recommended for <16GB RAM)
# When enabled, automatically uses q4_0 variants (e.g., llama3.1:8b-q4_0)
OLLAMA_USE_QUANTIZED=false

# ===================================
# LLAMAINDEX RAG
# ===================================
# Set to 'true' to use LlamaIndex RAG pipeline, 'false' for legacy implementation
USE_LLAMAINDEX=true
# Number of similar chunks to retrieve for RAG
SIMILARITY_TOP_K=5
# Response synthesis mode: compact, tree_summarize, simple_summarize

# ===================================
# QDRANT (VECTOR DATABASE)
# ===================================
# For Docker: use service name 'qdrant'
# For local development: use 'localhost'
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=code_chunks
# HNSW tuning (increase for larger corpora; defaults: ef_construct=100, m=16)
QDRANT_HNSW_EF_CONSTRUCT=100
QDRANT_HNSW_M=16
# Enable hybrid search (sparse + dense vectors) for new collections
ENABLE_HYBRID_SEARCH=true

# ===================================
# REDIS (CACHING)
# ===================================
# For Docker: use service name 'redis'
# For local development: use 'localhost'
REDIS_HOST=localhost
REDIS_PORT=6379
# Cache TTL in seconds
EMBEDDING_CACHE_TTL=86400  # 24 hours
QUERY_CACHE_TTL=3600       # 1 hour

# ===================================
# STORAGE
# ===================================
STORAGE_PATH=./data
LOG_LEVEL=INFO
LOG_PATH=./logs
UPLOAD_BASE_DIR=data/raw/uploaded
UPLOAD_MAX_FILE_SIZE_MB=50

# Allowed file extensions (comma-separated, no spaces)
ALLOWED_FILE_EXTENSIONS=.sql,.ddl,.csv,.json,.py,.ipynb

# ===================================
# LINEAGE PLUGINS
# ===================================
# Comma-separated plugin class paths
LINEAGE_PLUGINS=src.ingestion.plugins.sql_standard.StandardSqlPlugin,src.ingestion.plugins.python_treesitter.PythonTreesitterPlugin,src.ingestion.plugins.json_enricher.JsonEnricherPlugin
# Plugin configuration (JSON)
LINEAGE_PLUGIN_CONFIG_JSON={"src.ingestion.plugins.sql_standard.StandardSqlPlugin":{"default_dialect":"duckdb"},"src.ingestion.plugins.python_treesitter.PythonTreesitterPlugin":{"prefer_ast_for_small_files":true,"ast_max_lines":100,"sql_extraction_enabled":true}}

# ===================================
# DUCKDB (METADATA STORAGE)
# ===================================
# Mode: memory (with snapshots) or persistent (file-based)
DUCKDB_MODE=memory
DUCKDB_PATH=:memory:
DUCKDB_SNAPSHOT_INTERVAL_MINUTES=5
DUCKDB_SNAPSHOT_RETENTION_COUNT=5

# Connection Pool Configuration (Phase 1: Integration)
# Enable connection pooling for better concurrency (default: false for gradual rollout)
ENABLE_CONNECTION_POOL=false
CONNECTION_POOL_MAX_SIZE=5
CONNECTION_POOL_MIN_SIZE=1
CONNECTION_POOL_TIMEOUT=30.0
CONNECTION_POOL_MAX_IDLE_TIME=300.0
CONNECTION_POOL_HEALTH_CHECK_INTERVAL=60.0


# ===================================
# API CONFIGURATION
# ===================================
API_HOST=0.0.0.0
API_PORT=8000
# Set to 'true' for development hot-reload
API_RELOAD=false

# ===================================
# WEBSOCKET
# ===================================
WEBSOCKET_URL=ws://127.0.0.1:8000/admin/ws/dashboard

# ===================================
# GITHUB OAUTH (OPTIONAL)
# ===================================
# Register an app at https://github.com/settings/developers
GITHUB_CLIENT_ID=
GITHUB_CLIENT_SECRET=
GITHUB_REDIRECT_URI=http://localhost:8080/connectors/github/callback

# ===================================
# OBSERVABILITY (OPTIONAL - SIGNOZ/OTEL)
# ===================================
OTEL_ENABLED=false
OTEL_SERVICE_NAME=financial-lineage-backend
OTEL_EXPORTER_OTLP_ENDPOINT=

# ===================================
# RATE LIMITING (OPTIONAL)
# ===================================
# Per-user rate limits (requests per 10 minutes)
RATE_LIMIT_PER_USER=100

# Per-endpoint rate limits (requests per minute)
RATE_LIMIT_CHAT_DEEP=10
RATE_LIMIT_CHAT_SEMANTIC=30
RATE_LIMIT_FILES_UPLOAD=5

# ===================================
# AUDIT LOGGING (OPTIONAL)
# ===================================
# Log full query text (default: hash only for privacy)
AUDIT_LOG_FULL_QUERIES=false

# Audit log retention in days
AUDIT_LOG_RETENTION_DAYS=90

# ===================================
# DOCKER-SPECIFIC OVERRIDES
# ===================================
# These are automatically set by docker-compose.yml
# OLLAMA_HOST=http://host.docker.internal:11434
# QDRANT_HOST=qdrant
# REDIS_HOST=redis
# STORAGE_PATH=/app/data
